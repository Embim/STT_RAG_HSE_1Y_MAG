"""
–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ª–µ–∫—Ü–∏—è–º
"""

import weaviate
from collections import Counter


def get_stats():
    """–ü–æ–ª—É—á–∞–µ—Ç –∏ –≤—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –±–∞–∑–µ"""

    print("=" * 80)
    print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ë–ê–ó–ï –õ–ï–ö–¶–ò–ô")
    print("=" * 80)

    try:
        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        print("\n–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Weaviate...")
        client = weaviate.connect_to_local()
        print("‚úì –ü–æ–¥–∫–ª—é—á–µ–Ω–æ\n")

        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
        collection = client.collections.get("LectureChunks")

        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤
        print("üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        print("-" * 80)

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã
        all_objects = collection.query.fetch_objects(limit=10000)

        total_chunks = len(all_objects.objects)
        print(f"–í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤ –≤ –±–∞–∑–µ: {total_chunks}")

        if total_chunks == 0:
            print("\n‚ö† –ë–∞–∑–∞ –ø—É—Å—Ç–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞: python rag_pipeline.py")
            client.close()
            return

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ª–µ–∫—Ü–∏—è–º
        lecture_ids = []
        filenames = []
        total_words = 0

        for obj in all_objects.objects:
            props = obj.properties
            lecture_ids.append(props.get('lecture_id', 'unknown'))
            filenames.append(props.get('filename', 'unknown'))
            total_words += props.get('total_words', 0)

        # –ü–æ–¥—Å—á–µ—Ç
        lecture_counter = Counter(lecture_ids)
        unique_lectures = len(lecture_counter)

        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª–µ–∫—Ü–∏–π: {unique_lectures}")
        print(f"–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤ –Ω–∞ –ª–µ–∫—Ü–∏—é: {total_chunks / unique_lectures:.1f}")

        # –¢–æ–ø –ª–µ–∫—Ü–∏–π –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —á–∞–Ω–∫–æ–≤
        print("\n–¢–û–ü-10 –õ–ï–ö–¶–ò–ô –ü–û –ö–û–õ–ò–ß–ï–°–¢–í–£ –ß–ê–ù–ö–û–í")
        print("-" * 80)

        for lecture_id, count in lecture_counter.most_common(10):
            print(f"{lecture_id}: {count} —á–∞–Ω–∫–æ–≤")

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤
        print("\n –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –†–ê–ó–ú–ï–†–ê–ú")
        print("-" * 80)

        word_counts = []
        for obj in all_objects.objects:
            props = obj.properties
            words_in_chunk = props.get('word_end', 0) - props.get('word_start', 0)
            word_counts.append(words_in_chunk)

        if word_counts:
            avg_words = sum(word_counts) / len(word_counts)
            min_words = min(word_counts)
            max_words = max(word_counts)

            print(f"–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: {avg_words:.1f} —Å–ª–æ–≤")
            print(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {min_words} —Å–ª–æ–≤")
            print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {max_words} —Å–ª–æ–≤")

        # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ª–µ–∫—Ü–∏–π
        print("\n –°–ü–ò–°–û–ö –í–°–ï–• –õ–ï–ö–¶–ò–ô")
        print("-" * 80)

        unique_filenames = sorted(set(filenames))
        for i, filename in enumerate(unique_filenames, 1):
            chunks_count = lecture_counter.get(filename.replace('.json', ''), 0)
            print(f"{i:2d}. {filename} ({chunks_count} —á–∞–Ω–∫–æ–≤)")

        print("\n" + "=" * 80)

        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
        client.close()

    except Exception as e:
        print(f"\n‚úó –û—à–∏–±–∫–∞: {e}")
        print("\n–£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ:")
        print("1. Weaviate –∑–∞–ø—É—â–µ–Ω")
        print("2. –ë–∞–∑–∞ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∞ (python rag_pipeline.py)")


if __name__ == "__main__":
    get_stats()
